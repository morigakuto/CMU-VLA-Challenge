結論からいうと：


RTX 5080 (sm_120) を公式ホイールだけでちゃんと使える PyTorch

**Python 3.8 対応版は「存在しない」**です。
Python 3.10 対応版も、sm_120 をサポートするのは CUDA 12.8（cu128）のビルド以降だけで、
ご指定の cu118〜cu124（安定版＆nightly）には sm_120 対応ホイールはありません。

以下、インデックス別に整理します。




1. sm_120（Blackwell, RTX 5080）サポートの状況

各所の報告では、RTX 5080 など Blackwell 世代で PyTorch を動かすと：

NVIDIA GeForce RTX 5080 with CUDA capability sm_120 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_50 … sm_90.  

という警告が出て落ちる、という事例が多数です。
PyTorch チーム自身も、


「CUDA 12.8 でビルドされた PyTorch バイナリは Blackwell(sm_120) をサポートする」  
それ以前（たとえば 2.4.1 + cu124 など）は 最大でも sm_90 まで  

と説明しています。

さらに NVIDIA フォーラムでも、


CUDA 12.4（cu124）のバイナリには sm_120 が入っていない
sm_120 を含むのは cu128（= CUDA 12.8）ビルドの PyTorch

と明記されています。 

よって、

cu118〜cu124 の公式ホイール（stable / nightly 問わず）は RTX 5080 をネイティブにはサポートしていない

と見てよさそうです。




2. download.pytorch.org の安定版ホイール（cu118〜cu124）



cu118（CUDA 11.8 系）

https://download.pytorch.org/whl/cu118/torch/ にある公式ホイール 


対応バージョン：torch 2.0.0 〜 2.5.1
対応 Python：

3.8: 2.0.0〜2.4.1 まで cp38 ホイールあり
3.9: 2.0.0〜2.5.1 まで cp39 あり
3.10: 2.0.0〜2.5.1 まで cp310 あり
3.11: 2.0.0〜2.5.1 まで cp311 あり
3.12: 2.2.0 以降で cp312 あり
3.13: 2.5.0 以降で cp313 あり

→ Python 3.8 / 3.10 ともにホイールは豊富ですが、sm_120 非対応です（〜sm_90）。




cu121（CUDA 12.1 系）

https://download.pytorch.org/whl/cu121/torch/ 


対応バージョン：torch 2.1.0 〜 2.5.1
対応 Python：

3.8: 2.1.0〜2.4.1 まで cp38 あり
3.9: 2.1.0〜2.5.0 まで cp39 あり
3.10: 2.1.0〜2.5.1 まで cp310 あり
3.11: 2.1.0〜2.5.1 まで cp311 あり
3.12: 2.2.0〜2.5.1 で cp312 あり
3.13: 2.5.0〜2.5.1 で cp313 あり

→ ここも 3.8 / 3.10 両方 OK だが、アーキは sm_90 までです。




cu124（CUDA 12.4 系）

https://download.pytorch.org/whl/cu124/torch/ 


対応バージョン：現状 torch 2.4.0〜2.5.0 など
対応 Python：

3.8: cp38 ホイールあり（2.4.0〜2.4.1）
3.9: cp39 ホイールあり（2.4.0〜2.5.0）
3.10: cp310 ホイールあり
3.11: cp311 ホイールあり
3.12: cp312 ホイールあり
3.13: 2.5.0 から cp313 ホイールあり

NVIDIA 側の情報どおり、cu124 自体が sm_120 を含んでいないので、
これらも当然 RTX 50 系は非対応です。 




3. nightly インデックス（cu121 / cu122 / cu124）



nightly/cu121

https://download.pytorch.org/whl/nightly/cu121/torch/ 


一例：torch-2.6.0.dev20241112+cu121-...
対応 Python：

3.9 / 3.10 / 3.11 / 3.12 / 3.13 用ホイールあり
3.8 用ホイールは無し

→ ただし、CUDA 12.1 ビルドなので sm_120 はやはり未対応です。
（sm_120 が入るのは 12.8 以降との公式コメントあり  ）




nightly/cu124

https://download.pytorch.org/whl/nightly/cu124/torch/


一例：torch-2.7.0.dev20250310+cu124-...
対応 Python：

3.9 / 3.10 / 3.11 / 3.12 / 3.13 用ホイールあり
3.8 用は無し

→ こちらも CUDA 12.4 ビルドなので、前述の通り sm_120 は入っていません。 




nightly/cu122

https://download.pytorch.org/whl/nightly/cu122/ は、ツール経由では インデックス自体がエラーで内容を確認できませんでした（おそらく torch ホイールは置いていないか、非公開）。
ただし、PyTorch 側の sm_120 サポート議論でも 12.4 ですら未サポート、12.8 以降で対応という流れなので、仮にあっても sm_120 対応はないと見て良いと思います。 




4. PyPI 上の torch パッケージ

PyPI の torch 最新版は 2.9.1 で、メタデータ上の Requires-Python は >=3.10 となっており、
今のメインラインでは Python 3.8 は既にサポート外です。 


sm_120 対応は CUDA 12.8 (cu128) ビルドの PyTorch 2.8 以降に入っており、
それらの cu128 ホイールも cp310 以上のみ（3.10〜3.14）です。 
したがって、PyPI / download.pytorch.org いずれでも「sm_120 対応かつ Python 3.8 対応」の公式ホイールは存在しません。



5. まとめ（質問に対する直接の答え）

RTX 5080 (Compute Capability 12.0, sm_120) をサポートする公式 PyTorch ホイールは、
cu118〜cu124 の stable / nightly インデックスには存在しない。

これらはすべて sm_90 までのサポートで止まっています。 
Python 3.8 対応かつ sm_120 対応の公式ホイールは現時点で存在しません。

sm_120 対応は 2.8 以降 + CUDA 12.8（cu128）で導入されていますが、
これらは Python 3.10 以上のみ対応です。 
Python 3.10 で sm_120 を公式ホイールで使いたい場合

CUDA 12.8（cu128）版の torch（2.8 以降）を使う必要があります。
ご指定の cu121/122/124 の nightly だけでは RTX 5080 をフルに活かすことはできません。

もしこのあと、


「じゃあ RTX 5080 で実用的に動かすには、どの torch / CUDA / Python の組み合わせが良さそう？」
「Windows / Linux それぞれのインストールコマンドを知りたい」

みたいなところまで詰めたければ、その前提で組み合わせ候補を一緒に決めましょう。